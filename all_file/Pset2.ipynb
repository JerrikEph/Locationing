{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import argparse\n",
    "\n",
    "parser = argparse.ArgumentParser(description=\"training options\")\n",
    "parser.add_argument('--src-path', action='store', dest='src_path', required=True)\n",
    "parser.add_argument('--res-path', action='store', dest='res_path', required=True)\n",
    "parser.add_argument('--gpu-num', action='store', dest='gpu_num', required=True)\n",
    "parser.add_argument('--num-station', action='store', dest='num_station', required=True)\n",
    "args = parser.parse_args()\n",
    "\n",
    "filePath = args.src_path\n",
    "resPath = args.res_path\n",
    "num_station = int(args.num_station)\n",
    "gpu_num = args.gpu_num\n",
    "\n",
    "c = 3e8\n",
    "\n",
    "def get_top_k(file_name, save_file=None, top_k=10):\n",
    "\n",
    "    fin = open(file_name, 'rb')\n",
    "    base_dict = {}\n",
    "    top_k_toa = []\n",
    "    top_k_base = []\n",
    "    for line_idx, line in enumerate(fin):\n",
    "        if line_idx == 0:\n",
    "            N = int(line)\n",
    "        elif line_idx == 1:\n",
    "            M = int(line)\n",
    "        elif line_idx == 2:\n",
    "            pass\n",
    "        elif line_idx < 3+N:\n",
    "            base_dict[line_idx-3] = [float(x) for x in line.split()]\n",
    "        else:\n",
    "            toa_list = [(i, float(t)) for i, t in enumerate(line.split())]\n",
    "            # check\n",
    "            if len(toa_list) != N:\n",
    "                print 'wrong line!'\n",
    "                exit()\n",
    "            toa_list = sorted(toa_list, lambda x, y: cmp(x[1], y[1]))\n",
    "            cur_toa = []\n",
    "            cur_base = []\n",
    "            for (i, t) in toa_list[:top_k]:\n",
    "                cur_toa.append(t)\n",
    "                cur_base.append(base_dict[i])\n",
    "            top_k_toa.append(cur_toa)\n",
    "            top_k_base.append(cur_base)\n",
    "    if save_file is not None:\n",
    "        cPickle.dump([top_k_toa, top_k_base], open(save_file, 'wb'))\n",
    "    return top_k_toa, top_k_base, 3\n",
    "\n",
    "def loadRes(filePath):\n",
    "    with open(filePath, 'r') as fd:\n",
    "        device_cord = []\n",
    "        for line in fd:\n",
    "            cord = [np.float64(i) for i in line.split()]\n",
    "            device_cord.append(cord)\n",
    "    device_cord = np.array(device_cord)\n",
    "    return device_cord\n",
    "\n",
    "\n",
    "\n",
    "D, S, dimen = get_top_k(filePath, top_k=num_station)\n",
    "device_Dist = D*c\n",
    "\n",
    "cord_init = np.mean(S, axis=1)\n",
    "bias_init = np.zeros(len(D))\n",
    "\n",
    "\n",
    "with tf.device('/gpu:'+gpu_num):\n",
    "\n",
    "    cord = tf.Variable(cord_init, name='Cordinate') #(N,3)\n",
    "    Station = tf.constant(S, tf.float64) #(N, M,3)\n",
    "    bias = tf.Variable(bias_init, 'Bias') #(N, )\n",
    "\n",
    "    alpha1 = tf.Variable(np.ones(len(cord_init)), 'Alpha1', dtype = tf.float64)  #(N,)\n",
    "    alpha2 = tf.Variable(np.ones(len(cord_init)), 'Alpha2', dtype = tf.float64)  #(N,)\n",
    "    alpha3 = tf.Variable(np.ones(len(cord_init)), 'Alpha3', dtype = tf.float64)  #(N,)\n",
    "    beta1 = tf.Variable(np.ones(len(S)), 'Beta1', dtype = tf.float64)  #(M,)\n",
    "\n",
    "    D_dist = tf.constant(device_Dist, tf.float64)\n",
    "    mask = tf.constant([[[1, 1, 1]]], tf.float64)\n",
    "\n",
    "    expand_cord = tf.expand_dims(cord, 1) #(N, 1, 3)\n",
    "    expand_Station = Station #(N, M, 3)\n",
    "\n",
    "    expand_alpha1 = tf.expand_dims(alpha1, 1) #(N, 1)\n",
    "    expand_alpha2 = tf.expand_dims(alpha2, 1)\n",
    "    expand_alpha3 = tf.expand_dims(alpha3, 1)\n",
    "\n",
    "    expand_beta1 = tf.expand_dims(beta1, 0)\n",
    "\n",
    "    expand_bias = tf.expand_dims(bias, 1)\n",
    "\n",
    "    dist_2 = tf.reduce_sum((expand_cord - expand_Station)**2, 2) #(N, M)\n",
    "\n",
    "    global_step = tf.Variable(0, name='global_step', trainable=False)\n",
    "\n",
    "\n",
    "    # dist_hat = tf.sqrt(expand_alpha1**2 * dist_x +expand_alpha2**2 * dist_y +\n",
    "    #                    expand_alpha3**2 * dist_z) - expand_bias #(N,M)\n",
    "    # dist_hat = expand_alpha1 * tf.sqrt(dist_x + dist_y + expand_alpha2**2) - expand_bias #(N,M)\n",
    "    dist_hat = expand_alpha1 * tf.sqrt(dist_2) - expand_bias  #(N,M)\n",
    "\n",
    "\n",
    "    losses = tf.reduce_sum((dist_hat - D_dist) **2, 1)\n",
    "    learning_rate = tf.train.exponential_decay(0.5, global_step, 1000, 0.85, staircase=True) + tf.train.exponential_decay(1e-2, global_step, 5000, 0.85, staircase=True)\n",
    "    optimizer = tf.train.AdamOptimizer(learning_rate=learning_rate)\n",
    "    train_op = optimizer.minimize(losses, global_step=global_step)\n",
    "\n",
    "config=tf.ConfigProto()\n",
    "config.gpu_options.allow_growth = True\n",
    "config.allow_soft_placement = True\n",
    "# with tf.Session(config=config) as sess:\n",
    "sess = tf.Session(config=config)\n",
    "sess.run(tf.initialize_all_variables())\n",
    "for i in range(50000):\n",
    "    _, loss = sess.run([train_op, losses])\n",
    "    if i%1000 == 0:\n",
    "        print np.sum(loss), 'lr=', sess.run(learning_rate)\n",
    "B, P, a1 = sess.run([bias, cord, alpha1])\n",
    "\n",
    "with open(resPath, 'w') as fd:\n",
    "    if P.shape[1] ==3:\n",
    "        for i in range(len(P)):\n",
    "            fd.write('{}\\t{}\\t{}\\n'.format(P[i, 0], P[i, 1], P[i, 2]))\n",
    "    else:\n",
    "        for i in range(len(P)):\n",
    "            fd.write('{}\\t{}\\n'.format(P[i, 0], P[i, 1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
